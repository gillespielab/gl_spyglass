{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e48932",
   "metadata": {},
   "source": [
    "Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b22ee7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-18 17:03:11,973][INFO]: DataJoint 0.14.6 connected to gabby@gl-ash.biostr.washington.edu:3306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataJoint connection (connected) gabby@gl-ash.biostr.washington.edu:3306"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datajoint as dj\n",
    "\n",
    "dj.config[\"database.host\"] = \"gl-ash.biostr.washington.edu\"\n",
    "dj.config[\"database.user\"] = \"gabby\"\n",
    "dj.config[\"database.port\"] = 3306\n",
    "\n",
    "dj.conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0e0d4",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24c1007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import ghostipy as gsp\n",
    "\n",
    "import spyglass.common as sgc\n",
    "import spyglass.lfp as lfp\n",
    "\n",
    "import figpack.views as vv\n",
    "\n",
    "from gl_spyglass.utils.common_neural_functions import validate_references, apply_referencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "243ec1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['FIGPACK_BUCKET'] = 'gillespielab'\n",
    "\n",
    "# TODO: update this with your own custom FIGPACK_API_KEY (contact Jeremy Magland if you don't have one)\n",
    "os.environ['FIGPACK_API_KEY'] = '17979e3bc8880ea91520c1dc2e8ab6a97fc665893fe2728e9d642923c3dcf31c'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c436661",
   "metadata": {},
   "source": [
    "Select subj, date, epoch to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd288fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = 'pippin'\n",
    "date = 20210421\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444df63e",
   "metadata": {},
   "source": [
    "Set plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af18efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_on = False\n",
    "save_dir = '/home/gl-willow/Documents/gabby/gabby_analysis_gillespie/results/old_young_results/sleep_spectrograms/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846bf88",
   "metadata": {},
   "source": [
    "Calculate average CA1 spectrogram\n",
    "\n",
    "Note: can use this code to calculate the spectrogram for any group of electrodes, just select the ones you want (i.e. only the strongest SWR CA1 electrodes, only the cortical electrodes, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "371eef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set corresponding nwb_file_name and interval_list_name\n",
    "nwb_file_name = f'{subj}{date}_.nwb'\n",
    "interval_list_name = (\n",
    "    sgc.TaskEpoch() & {\"nwb_file_name\": nwb_file_name, \"epoch\": epoch}\n",
    ").fetch1(\"interval_list_name\")\n",
    "pos_interval_list_name = (\n",
    "    sgc.IntervalList()\n",
    "    & {\"nwb_file_name\": nwb_file_name, \"pipeline\": \"position\"}\n",
    ").fetch(\"interval_list_name\")[epoch - 1]\n",
    "\n",
    "# load in one electrode per electrode group for ca1 region, excluding bad channels\n",
    "electrodes_df, val_can_refs = validate_references(nwb_file_name, is_copy=True)\n",
    "electrodes_df = electrodes_df[electrodes_df['bad_channel'] == 'False']\n",
    "electrodes_df = pd.DataFrame(\n",
    "    [\n",
    "        electrodes_df[electrodes_df['electrode_group_name'] == i].iloc[0]\n",
    "        for i in np.unique(electrodes_df['electrode_group_name'].values)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# load in lfp\n",
    "good_elecs_df = electrodes_df[\n",
    "    (electrodes_df['bad_channel'] == 'False')\n",
    "]\n",
    "good_single_elecs_df = pd.DataFrame(\n",
    "    [\n",
    "        good_elecs_df[good_elecs_df[\"electrode_group_name\"] == i].iloc[0]\n",
    "        for i in np.unique(good_elecs_df[\"electrode_group_name\"].values)\n",
    "    ]\n",
    ")\n",
    "good_single_elecs = good_single_elecs_df['electrode_id'].values\n",
    "lfp_electrode_group_name = 'good_single_elecs'\n",
    "\n",
    "lfp_sampling_rate = 1_000\n",
    "\n",
    "lfp_filter_name = 'LFP 0-400 Hz'\n",
    "lfp_s_key = {\n",
    "    'nwb_file_name': nwb_file_name,\n",
    "    'lfp_electrode_group_name': lfp_electrode_group_name,\n",
    "    'target_interval_list_name': interval_list_name,\n",
    "    'filter_name': lfp_filter_name,\n",
    "    'filter_sampling_rate': 30_000,  # sampling rate of the data (Hz)\n",
    "    'target_sampling_rate': lfp_sampling_rate,  # sampling rate of the lfp output (Hz)\n",
    "}\n",
    "\n",
    "lfp_merge_id = (lfp.LFPOutput.LFPV1() & lfp_s_key).fetch1('merge_id')\n",
    "lfp_key = {\n",
    "    'merge_id': lfp_merge_id,\n",
    "}\n",
    "lfp_df = (lfp.LFPOutput & lfp_key).fetch1_dataframe()\n",
    "lfp_df.columns = good_single_elecs  # rename lfp columns to their original elec ids\n",
    "\n",
    "# apply referencing if referencing is on\n",
    "if ref_on:\n",
    "    lfp_df = apply_referencing(lfp_df, electrodes_df)\n",
    "\n",
    "# get the start time of interval list to align with lfp time\n",
    "int_start_time, int_end_time = (sgc.IntervalList() & {'nwb_file_name': nwb_file_name, 'interval_list_name': interval_list_name}).fetch1('valid_times')[0]\n",
    "start_time_sec = lfp_df.index[0] - int_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b8498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exists!\n"
     ]
    }
   ],
   "source": [
    "# GENERATE CA1 SPECTROGRAM\n",
    "# select all ca1 electrodes\n",
    "all_ca1_elecs = electrodes_df.loc[electrodes_df['region_name'] == 'ca1', 'electrode_id'].values\n",
    "\n",
    "# calculate for just one electrode first to get the right frequency and time bins\n",
    "elec = all_ca1_elecs[0]\n",
    "elec_df = lfp_df[elec]\n",
    "\n",
    "data = elec_df.values\n",
    "\n",
    "fs = lfp_sampling_rate\n",
    "\n",
    "timestamps = elec_df.index.values - elec_df.index.values[0]\n",
    "\n",
    "coefs_cwt, _, f_cwt, t_cwt, _ = gsp.cwt(data=data,\n",
    "                                freq_limits=[0.5, 200],\n",
    "                                fs=fs,\n",
    "                                timestamps=timestamps)\n",
    "\n",
    "psd_cwt = coefs_cwt.real**2 + coefs_cwt.imag**2\n",
    "psd_cwt /= np.max(psd_cwt)\n",
    "\n",
    "spectral_sampling_rate = 1 / np.mean(np.diff(t_cwt))\n",
    "\n",
    "# load in avg ca1 spectrogram if it already exists, otherwise calculate and save\n",
    "if os.path.exists(os.path.join(save_dir, f'{nwb_file_name}_{interval_list_name}_avg_ca1_psd.npy')):\n",
    "    print('already exists!')\n",
    "    avg_ca1_psd = np.load(os.path.join(save_dir, f'{nwb_file_name}_{interval_list_name}_avg_ca1_psd.npy'))\n",
    "else:\n",
    "    print('calculating avg ca1 psd...')\n",
    "    all_psds = np.zeros((len(all_ca1_elecs), psd_cwt.shape[0], psd_cwt.shape[1]))\n",
    "\n",
    "    for e, elec in tqdm(enumerate(all_ca1_elecs)):\n",
    "        data = lfp_df[elec].values\n",
    "        coefs_cwt, _, f_cwt, t_cwt, _ = gsp.cwt(data=data,\n",
    "                                    freq_limits=[0.5, 200],\n",
    "                                    fs=fs,\n",
    "                                    timestamps=timestamps)\n",
    "\n",
    "        psd_cwt = coefs_cwt.real**2 + coefs_cwt.imag**2\n",
    "        psd_cwt /= np.max(psd_cwt)\n",
    "        all_psds[e] = psd_cwt\n",
    "\n",
    "    avg_ca1_psd = all_psds.mean(axis=0)\n",
    "    np.save(os.path.join(save_dir, f'{nwb_file_name}_{interval_list_name}_avg_ca1_psd.npy'),\n",
    "            avg_ca1_psd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6848a5",
   "metadata": {},
   "source": [
    "Plot and show spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f867a1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored Spectrogram with 5 downsampled levels:\n",
      "  Original: (1811725, 87) (chunks: (8192, 87))\n",
      "  Factor 4: (452932, 87) (chunks: (8192, 87))\n",
      "  Factor 16: (113233, 87) (chunks: (8192, 87))\n",
      "  Factor 64: (28309, 87) (chunks: (8192, 87))\n",
      "  Factor 256: (7078, 87) (chunks: (7078, 87))\n",
      "  Factor 1024: (1770, 87) (chunks: (1770, 87))\n",
      "Found 13 files to upload, total size: 617.51 MB\n",
      "Uploading 13 files in batches of 20 with up to 16 concurrent uploads per batch...\n",
      "Processing batch 1/1 (13 files)...\n",
      "Uploaded 1/13: assets/index-GPjx4QpG.css\n",
      "Uploaded 2/13: extension_manifest.json\n",
      "Uploaded 3/13: assets/neurosift-logo-CLsuwLMO.png\n",
      "Uploaded 4/13: data.zarr/.zmetadata\n",
      "Uploaded 5/13: index.html\n",
      "Uploaded 6/13: assets/index-BY1Hwjm4.js\n",
      "Uploaded 7/13: data.zarr/_consolidated_6.dat\n",
      "Uploaded 8/13: data.zarr/_consolidated_0.dat\n",
      "Uploaded 9/13: data.zarr/_consolidated_2.dat\n",
      "Uploaded 10/13: data.zarr/_consolidated_5.dat\n",
      "Uploaded 11/13: data.zarr/_consolidated_1.dat\n",
      "Uploaded 12/13: data.zarr/_consolidated_4.dat\n",
      "Uploaded 13/13: data.zarr/_consolidated_3.dat\n",
      "Creating manifest...\n",
      "Total size: 617.51 MB\n",
      "Uploading manifest.json...\n",
      "Finalizing figure...\n",
      "Upload completed successfully\n",
      "View the figure at: https://gillespielab.figpack.org/figures/default/0f174fb7e425f42cee1da275/index.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://gillespielab.figpack.org/figures/default/0f174fb7e425f42cee1da275/index.html'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_ca1_spectrogram = vv.Spectrogram(\n",
    "    start_time_sec=start_time_sec,\n",
    "    sampling_frequency_hz=spectral_sampling_rate,\n",
    "    frequencies=f_cwt[::-1],\n",
    "    data=avg_ca1_psd[::-1, :].T,\n",
    ")\n",
    "avg_ca1_spectrogram.show(title=f\"{nwb_file_name} {interval_list_name} {'referenced' if ref_on else 'unreferenced'} avg CA1 spectrogram\", upload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead7d9f2",
   "metadata": {},
   "source": [
    "Combine with any other views you want!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79459a7f",
   "metadata": {},
   "source": [
    "Keep in mind you can also play with the frequency bins and frequency limits within the ghostipy continuous wavelet transform function (`gsp.cwt`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gabby_spyglass_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
